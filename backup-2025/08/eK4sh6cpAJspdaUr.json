{
  "active": true,
  "connections": {
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Add File to Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Google Gemini": {
      "ai_embedding": [
        [
          {
            "node": "Add File to Vector Store",
            "type": "ai_embedding",
            "index": 0
          },
          {
            "node": "Retrieve File(s) from Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Postgres Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Get an execution",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upload File": {
      "main": [
        [
          {
            "node": "Add File to Vector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Reranker Cohere": {
      "ai_reranker": [
        [
          {
            "node": "Retrieve File(s) from Vector Store",
            "type": "ai_reranker",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retrieve File(s) from Vector Store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Add File to Vector Store": {
      "main": [
        []
      ]
    },
    "Code2": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get an execution": {
      "main": [
        [
          {
            "node": "Code2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2025-08-06T05:34:34.712Z",
  "id": "eK4sh6cpAJspdaUr",
  "isArchived": false,
  "meta": {
    "templateId": "rag-starter-template",
    "templateCredsSetupCompleted": true
  },
  "name": "RAG Test",
  "nodes": [
    {
      "parameters": {
        "dataType": "binary",
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "filename",
                "value": "={{ $json['Upload your file(s)'][0].filename }}"
              }
            ]
          }
        }
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        16,
        1320
      ],
      "id": "94aecac0-03f9-4915-932b-d14a2576607b",
      "name": "Default Data Loader"
    },
    {
      "parameters": {
        "options": {
          "returnIntermediateSteps": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2,
      "position": [
        -176,
        384
      ],
      "id": "579aed76-9644-42d1-ac13-7369059ff1c2",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "public": true,
        "options": {
          "allowFileUploads": false,
          "loadPreviousSession": "notSupported",
          "responseMode": "responseNode"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -432,
        592
      ],
      "id": "9c30de61-935a-471f-ae88-ec5f67beeefc",
      "name": "When chat message received",
      "webhookId": "4091fa09-fb9a-4039-9411-7104d213f601"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "typeVersion": 1,
      "position": [
        80,
        816
      ],
      "id": "0047e212-7efc-435e-a2b2-d0bb53bd9315",
      "name": "Embeddings Google Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "SXxerOXC902v1BV6",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -208,
        608
      ],
      "id": "d4f789c1-921a-4f7c-9496-e0eb4beaf341",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "SXxerOXC902v1BV6",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "typeVersion": 1.3,
      "position": [
        -80,
        608
      ],
      "id": "351e447b-9658-41ea-8251-99b76fea65bf",
      "name": "Postgres Chat Memory",
      "credentials": {
        "postgres": {
          "id": "63Uzmf3H0VuXxdXP",
          "name": "BakaWorld DB"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://192.168.0.107:8100/log_eval",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "question",
              "value": "={{ $json.question }}"
            },
            {
              "name": "context",
              "value": "={{ $json.context }}"
            },
            {
              "name": "answer",
              "value": "={{ $json.answer }}"
            },
            {
              "name": "filename",
              "value": "={{ $json.filename }}"
            },
            {
              "name": "metadata",
              "value": "={{ $json.metadata }}"
            },
            {
              "name": "documentType",
              "value": "={{ $json.documentType }}"
            },
            {
              "name": "retrieval",
              "value": "={{ $json.retrieval }}"
            },
            {
              "name": "generation",
              "value": "={{ $json.generation }}"
            },
            {
              "name": "performance",
              "value": "={{ $json.performance }}"
            },
            {
              "name": "user",
              "value": "={{ $json.user }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1120,
        688
      ],
      "id": "bb5dbd1e-5834-433b-bf2f-181f24685629",
      "name": "HTTP Request"
    },
    {
      "parameters": {
        "formTitle": "Upload your data to test RAG",
        "formFields": {
          "values": [
            {
              "fieldLabel": "Upload your file(s)",
              "fieldType": "file",
              "acceptFileTypes": ".pdf, .csv",
              "requiredField": true
            }
          ]
        },
        "options": {
          "respondWithOptions": {
            "values": {
              "respondWith": "redirect",
              "redirectUrl": "https://bakaflow.gleeze.com/webhook/4091fa09-fb9a-4039-9411-7104d213f601/chat"
            }
          }
        }
      },
      "type": "n8n-nodes-base.formTrigger",
      "typeVersion": 2.2,
      "position": [
        -432,
        1096
      ],
      "id": "f7a656ec-83fc-4ed2-a089-57a9def662b7",
      "name": "Upload File",
      "webhookId": "82848bc4-5ea2-4e5a-8bb6-3c09b94a8c5d"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "typeVersion": 1,
      "position": [
        208,
        816
      ],
      "id": "5a362027-1a0a-4092-9956-cd60f9b21113",
      "name": "Reranker Cohere",
      "credentials": {
        "cohereApi": {
          "id": "Be5I4bv9zqeP9A53",
          "name": "CohereApi account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "const observation = JSON.parse($('AI Agent').first().json.intermediateSteps[0].observation);\nconst contextChunks = [];\nconst filenames = new Set();\nconst documentTypes = new Set();\n\n// Enhanced data extraction\nfor (const entry of observation) {\n  try {\n    const obj = JSON.parse(entry.text);\n\n    // Extract context\n    if (obj.pageContent) {\n      contextChunks.push(obj.pageContent);\n    }\n\n    // Extract filename and document type\n    const filename =\n      obj?.metadata?.filename ||\n      obj?.metadata?.pdf?.info?.Title ||\n      \"unknown.pdf\";\n\n    if (filename && filename !== \"unknown.pdf\") {\n      filenames.add(filename);\n\n      // Extract document type from filename extension\n      const extension = filename.split(\".\").pop()?.toLowerCase();\n      if (extension) {\n        documentTypes.add(extension);\n      }\n    }\n  } catch (e) {\n    console.warn(\"Failed to parse entry:\", e.message);\n    continue;\n  }\n}\n\n// Build context with source attribution\nconst context = contextChunks.join(\"\\n\\n\");\nconst filename = [...filenames][0] || \"unknown.pdf\";\nconst documentType = [...documentTypes][0] || \"unknown\";\nconst question = $(\"When chat message received\").first().json.chatInput;\nconst answer = $('AI Agent').first().json.output;\n\n// Calculate context quality metrics\nconst contextMetrics = {\n  totalChunks: contextChunks.length,\n  totalLength: context.length,\n  avgChunkLength:\n    contextChunks.length > 0\n      ? Math.round(context.length / contextChunks.length)\n      : 0,\n  uniqueFilenames: filenames.size,\n};\n\n// Enhanced logging for debugging\nconsole.log(\"Context Extraction Summary:\", {\n  filename: filename,\n  documentType: documentType,\n  metrics: contextMetrics,\n  questionLength: question?.length || 0,\n  answerLength: answer?.length || 0,\n});\n\n// Return enhanced payload for Phoenix with retrieval and generation metrics\nreturn [\n  {\n    json: {\n      question: question || \"\",\n      context: context || \"\",\n      answer: answer || \"\",\n      filename: filename,\n      documentType: documentType,\n\n      // Core metadata\n      metadata: {\n        contextMetrics: contextMetrics,\n        timestamp: new Date().toISOString(),\n        workflow: \"n8n-rag-system\",\n        version: \"1.0\",\n      },\n\n      // Retrieval info (you can extract from your vector search step)\n      retrieval: {\n        topK: contextChunks.length,\n        retrievalLatency: null, // Add timing if available\n        vectorStore: \"n8n_vectors\",\n      },\n\n      // Generation info (extract from your LLM node)\n      generation: {\n        model: \"gemini-2.5-flash\", // Or extract from your model node\n        temperature: 0.1, // Extract from your settings\n        generationLatency: $input.first().json.generationLatency, // Add timing if available\n      },\n\n      // Session tracking\n      user: {\n        sessionId:\n          $(\"When chat message received\").first().json.sessionId || \"unknown\",\n        conversationId: $workflow.id, // Use workflow execution ID as conversation ID\n      },\n\n      performance: {\n        totalLatency: $input.first().json.totalLatency,\n        workflowStartTime: $input.first().json.workflowStartTime,\n        executionId: $input.first().json.executionId,\n      },\n    },\n  },\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        896,
        688
      ],
      "id": "394391b6-8894-4cb9-8c5c-d96535c03c48",
      "name": "Code"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"output\": {{ $json.output }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.4,
      "position": [
        672,
        496
      ],
      "id": "1fcb48d5-1c7a-4eb7-9ad5-ed6ec57ff4c9",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "mode": "insert",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.3,
      "position": [
        -80,
        1096
      ],
      "id": "c2579249-ed02-49f6-a1c3-1123b2da05d2",
      "name": "Add File to Vector Store",
      "credentials": {
        "postgres": {
          "id": "d2lXGCTjZwwS5QLF",
          "name": "n8n DataBase"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Use this knowledge base to answer questions from the user",
        "topK": 10,
        "useReranker": true,
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePGVector",
      "typeVersion": 1.3,
      "position": [
        48,
        608
      ],
      "id": "b53757c8-36d4-462d-937f-069aa01fceed",
      "name": "Retrieve File(s) from Vector Store",
      "credentials": {
        "postgres": {
          "id": "d2lXGCTjZwwS5QLF",
          "name": "n8n DataBase"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "let output = JSON.stringify($input.first().json.output);\n\nreturn [\n  {\n    json: {\n      output: output\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        448,
        496
      ],
      "id": "279f98a4-5416-4429-9564-d1551a8b946d",
      "name": "Code1"
    },
    {
      "parameters": {
        "jsCode": "// Helper function to get node execution time from runData\nfunction getNodeLatency(nodeName) {\n  try {\n    const executionData = $input.first().json;\n    const runData = executionData?.data?.resultData?.runData;\n    \n    if (runData && runData[nodeName] && runData[nodeName][0]) {\n      return runData[nodeName][0].executionTime;\n    }\n    return null;\n  } catch (e) {\n    return null;\n  }\n}\n\n// Get workflow timing from execution data\nconst executionData = $input.first().json;\nconst startedAt = new Date(executionData.startedAt).getTime();\nconst stoppedAt = new Date(executionData.stoppedAt).getTime();\nconst totalLatency = stoppedAt - startedAt;\n\n// Get specific node execution times\nconst aiAgentLatency = getNodeLatency('AI Agent');\nconst vectorSearchLatency = getNodeLatency('Retrieve File(s) from Vector Store');\nconst postgresMemoryLatency = getNodeLatency('Postgres Chat Memory');\nconst embeddingLatency = getNodeLatency('Embeddings Google Gemini');\nconst rerankLatency = getNodeLatency('Reranker Cohere');\n\n// Calculate retrieval and generation latencies\nlet retrievalLatency = null;\nlet generationLatency = null;\n\n// Sum up retrieval-related operations\nif (vectorSearchLatency || embeddingLatency || rerankLatency) {\n  retrievalLatency = (vectorSearchLatency || 0) + (embeddingLatency || 0) + (rerankLatency || 0);\n}\n\n// Generation is primarily the AI Agent\nif (aiAgentLatency) {\n  generationLatency = aiAgentLatency;\n}\n\n// Fallback calculations if specific timings aren't available\nif (!retrievalLatency) {\n  retrievalLatency = Math.round(totalLatency * 0.3); // 30% estimate\n}\n\nif (!generationLatency) {\n  generationLatency = Math.round(totalLatency * 0.6); // 60% estimate  \n}\n\n// Debug logging\nconsole.log(\"Timing Calculation Results:\", {\n  totalLatency: totalLatency + \"ms\",\n  retrievalLatency: retrievalLatency + \"ms\", \n  generationLatency: generationLatency + \"ms\",\n  nodeBreakdown: {\n    aiAgent: aiAgentLatency ? aiAgentLatency + \"ms\" : \"not available\",\n    vectorSearch: vectorSearchLatency ? vectorSearchLatency + \"ms\" : \"not available\",\n    postgresMemory: postgresMemoryLatency ? postgresMemoryLatency + \"ms\" : \"not available\",\n    embeddings: embeddingLatency ? embeddingLatency + \"ms\" : \"not available\",\n    reranker: rerankLatency ? rerankLatency + \"ms\" : \"not available\"\n  },\n  executionInfo: {\n    startedAt: executionData.startedAt,\n    stoppedAt: executionData.stoppedAt,\n    status: executionData.status,\n    executionId: executionData.id\n  }\n});\n\n// Return just the timing data\nreturn [\n  {\n    json: {\n      totalLatency: totalLatency,\n      retrievalLatency: retrievalLatency,\n      generationLatency: generationLatency,\n      workflowStartTime: executionData.startedAt,\n      workflowEndTime: executionData.stoppedAt,\n      calculatedAt: new Date().toISOString(),\n      executionId: executionData.id,\n      \n      // Detailed node timings for analysis\n      nodeTimings: {\n        aiAgent: aiAgentLatency,\n        vectorSearch: vectorSearchLatency,\n        postgresMemory: postgresMemoryLatency,\n        embeddings: embeddingLatency,\n        reranker: rerankLatency\n      },\n      \n      // Execution metadata\n      executionInfo: {\n        status: executionData.status,\n        mode: executionData.mode,\n        retryOf: executionData.retryOf\n      }\n    }\n  }\n];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        672,
        688
      ],
      "id": "3c4dfccb-46f2-476d-9cc6-5949f8a56f54",
      "name": "Code2"
    },
    {
      "parameters": {
        "resource": "execution",
        "operation": "get",
        "executionId": "=36432",
        "options": {
          "activeWorkflows": true
        },
        "requestOptions": {}
      },
      "type": "n8n-nodes-base.n8n",
      "typeVersion": 1,
      "position": [
        448,
        688
      ],
      "id": "12a0bd66-924e-4e63-93ab-0963e3723ea9",
      "name": "Get an execution",
      "credentials": {
        "n8nApi": {
          "id": "r6YUYcdGxuCEJVEe",
          "name": "n8n account"
        }
      }
    }
  ],
  "pinData": {
    "Upload File": [
      {
        "json": {
          "Upload your file(s)": [
            {
              "filename": "p17.pdf",
              "mimetype": "application/pdf",
              "size": 3046757
            }
          ],
          "submittedAt": "2025-08-06T12:57:04.449-04:00",
          "formMode": "production"
        }
      }
    ]
  },
  "repo_name": "n8n-backup",
  "repo_owner": "trazonm",
  "repo_path": "backup-",
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 2,
  "updatedAt": "2025-08-06T23:02:20.000Z",
  "versionId": "c2616d3b-6af4-479e-a1d8-f6e240495f30"
}